<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Requests高级 | Felix's Blog</title><meta name=keywords content><meta name=description content="

简历模板下载拓展


  import requests
  from lxml import etree
  import os
  headers = {
      'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36',

  }
  #创建一个新的文件夹
  dirName = 'jianli'
  if not os.path.exists(dirName):
      os.mkdir(dirName)

  #通用的url模板
  url = 'https://sc.chinaz.com/jianli/free_%d.html'
  for page in range(1,11):
      if page == 1:
          new_url = 'https://sc.chinaz.com/jianli/free.html'
      else:
          new_url = format(url%page)
      response = requests.get(url=new_url,headers=headers)
      response.encoding = 'utf-8'
      page_text = response.text
      #数据解析：详情页url和简历名称
      tree = etree.HTML(page_text)
      div_list = tree.xpath('//*[@id=&#34;container&#34;]/div')
      #局部解析
      for div in div_list:
          detail_url = 'https:'+div.xpath('./a/@href')[0]
          title = div.xpath('./p/a/text()')[0]+'.rar'
          # print(title,detail_url)
          #对详情页的url发起请求，解析出简历的下载地址
          detail_page_text = requests.get(url=detail_url,headers=headers).text
          #数据解析：解析下载地址
          detail_tree = etree.HTML(detail_page_text)
          li_list = detail_tree.xpath('//*[@id=&#34;down&#34;]/div[2]/ul/li')
          down_list = [] #存储不同的12个下载地址
          for li in li_list:
              download_link = li.xpath('./a/@href')[0]
              down_list.append(download_link)
          #随机选择一个下载地址进行简历模板的下载
          import random
          #从列表中随机选出一个下载地址
          link = random.choice(down_list)
          #对下载地址进行请求发送，下载简历模板的压缩包
          data = requests.get(url=link,headers=headers).content
          filePath = dirName+'/'+title
          with open(filePath,'wb') as fp:
              fp.write(data)
          print(title,'下载保存成功！')


Cookie


什么是cookie？"><meta name=author content="
作者:Felix"><link rel=canonical href=https://canw0916.github.io/en/posts/tech/requests%E9%AB%98%E7%BA%A7/><link crossorigin=anonymous href=/assets/css/stylesheet.67971badef1fb278a7dbb01fdd6e1add4dae2ea34bb3a44665b66327fad3f0ab.css integrity="sha256-Z5cbre8fsnin27Af3W4a3U2uLqNLs6RGZbZjJ/rT8Ks=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://canw0916.github.io/img/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://canw0916.github.io/img/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://canw0916.github.io/img/favicon-32x32.png><link rel=apple-touch-icon href=https://canw0916.github.io/img/apple-touch-icon.png><link rel=mask-icon href=https://canw0916.github.io/img/android-chrome-512x512.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://canw0916.github.io/en/posts/tech/requests%E9%AB%98%E7%BA%A7/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-7ENSZ7BS0C"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-7ENSZ7BS0C")}</script><meta property="og:title" content="Requests高级"><meta property="og:description" content="

简历模板下载拓展


  import requests
  from lxml import etree
  import os
  headers = {
      'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36',

  }
  #创建一个新的文件夹
  dirName = 'jianli'
  if not os.path.exists(dirName):
      os.mkdir(dirName)

  #通用的url模板
  url = 'https://sc.chinaz.com/jianli/free_%d.html'
  for page in range(1,11):
      if page == 1:
          new_url = 'https://sc.chinaz.com/jianli/free.html'
      else:
          new_url = format(url%page)
      response = requests.get(url=new_url,headers=headers)
      response.encoding = 'utf-8'
      page_text = response.text
      #数据解析：详情页url和简历名称
      tree = etree.HTML(page_text)
      div_list = tree.xpath('//*[@id=&#34;container&#34;]/div')
      #局部解析
      for div in div_list:
          detail_url = 'https:'+div.xpath('./a/@href')[0]
          title = div.xpath('./p/a/text()')[0]+'.rar'
          # print(title,detail_url)
          #对详情页的url发起请求，解析出简历的下载地址
          detail_page_text = requests.get(url=detail_url,headers=headers).text
          #数据解析：解析下载地址
          detail_tree = etree.HTML(detail_page_text)
          li_list = detail_tree.xpath('//*[@id=&#34;down&#34;]/div[2]/ul/li')
          down_list = [] #存储不同的12个下载地址
          for li in li_list:
              download_link = li.xpath('./a/@href')[0]
              down_list.append(download_link)
          #随机选择一个下载地址进行简历模板的下载
          import random
          #从列表中随机选出一个下载地址
          link = random.choice(down_list)
          #对下载地址进行请求发送，下载简历模板的压缩包
          data = requests.get(url=link,headers=headers).content
          filePath = dirName+'/'+title
          with open(filePath,'wb') as fp:
              fp.write(data)
          print(title,'下载保存成功！')


Cookie


什么是cookie？"><meta property="og:type" content="article"><meta property="og:url" content="https://canw0916.github.io/en/posts/tech/requests%E9%AB%98%E7%BA%A7/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-02-10T14:04:30+08:00"><meta property="article:modified_time" content="2023-02-10T14:04:30+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Requests高级"><meta name=twitter:description content="

简历模板下载拓展


  import requests
  from lxml import etree
  import os
  headers = {
      'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36',

  }
  #创建一个新的文件夹
  dirName = 'jianli'
  if not os.path.exists(dirName):
      os.mkdir(dirName)

  #通用的url模板
  url = 'https://sc.chinaz.com/jianli/free_%d.html'
  for page in range(1,11):
      if page == 1:
          new_url = 'https://sc.chinaz.com/jianli/free.html'
      else:
          new_url = format(url%page)
      response = requests.get(url=new_url,headers=headers)
      response.encoding = 'utf-8'
      page_text = response.text
      #数据解析：详情页url和简历名称
      tree = etree.HTML(page_text)
      div_list = tree.xpath('//*[@id=&#34;container&#34;]/div')
      #局部解析
      for div in div_list:
          detail_url = 'https:'+div.xpath('./a/@href')[0]
          title = div.xpath('./p/a/text()')[0]+'.rar'
          # print(title,detail_url)
          #对详情页的url发起请求，解析出简历的下载地址
          detail_page_text = requests.get(url=detail_url,headers=headers).text
          #数据解析：解析下载地址
          detail_tree = etree.HTML(detail_page_text)
          li_list = detail_tree.xpath('//*[@id=&#34;down&#34;]/div[2]/ul/li')
          down_list = [] #存储不同的12个下载地址
          for li in li_list:
              download_link = li.xpath('./a/@href')[0]
              down_list.append(download_link)
          #随机选择一个下载地址进行简历模板的下载
          import random
          #从列表中随机选出一个下载地址
          link = random.choice(down_list)
          #对下载地址进行请求发送，下载简历模板的压缩包
          data = requests.get(url=link,headers=headers).content
          filePath = dirName+'/'+title
          with open(filePath,'wb') as fp:
              fp.write(data)
          print(title,'下载保存成功！')


Cookie


什么是cookie？"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"📚文章","item":"https://canw0916.github.io/en/posts/"},{"@type":"ListItem","position":2,"name":"🚀 技术","item":"https://canw0916.github.io/en/posts/tech/"},{"@type":"ListItem","position":3,"name":"Requests高级","item":"https://canw0916.github.io/en/posts/tech/requests%E9%AB%98%E7%BA%A7/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Requests高级","name":"Requests高级","description":" 简历模板下载拓展\nimport requests from lxml import etree import os headers = { \u0026#39;User-Agent\u0026#39;:\u0026#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36\u0026#39;, } #创建一个新的文件夹 dirName = \u0026#39;jianli\u0026#39; if not os.path.exists(dirName): os.mkdir(dirName) #通用的url模板 url = \u0026#39;https://sc.chinaz.com/jianli/free_%d.html\u0026#39; for page in range(1,11): if page == 1: new_url = \u0026#39;https://sc.chinaz.com/jianli/free.html\u0026#39; else: new_url = format(url%page) response = requests.get(url=new_url,headers=headers) response.encoding = \u0026#39;utf-8\u0026#39; page_text = response.text #数据解析：详情页url和简历名称 tree = etree.HTML(page_text) div_list = tree.xpath(\u0026#39;//*[@id=\u0026#34;container\u0026#34;]/div\u0026#39;) #局部解析 for div in div_list: detail_url = \u0026#39;https:\u0026#39;+div.xpath(\u0026#39;./a/@href\u0026#39;)[0] title = div.xpath(\u0026#39;./p/a/text()\u0026#39;)[0]+\u0026#39;.rar\u0026#39; # print(title,detail_url) #对详情页的url发起请求，解析出简历的下载地址 detail_page_text = requests.get(url=detail_url,headers=headers).text #数据解析：解析下载地址 detail_tree = etree.HTML(detail_page_text) li_list = detail_tree.xpath(\u0026#39;//*[@id=\u0026#34;down\u0026#34;]/div[2]/ul/li\u0026#39;) down_list = [] #存储不同的12个下载地址 for li in li_list: download_link = li.xpath(\u0026#39;./a/@href\u0026#39;)[0] down_list.append(download_link) #随机选择一个下载地址进行简历模板的下载 import random #从列表中随机选出一个下载地址 link = random.choice(down_list) #对下载地址进行请求发送，下载简历模板的压缩包 data = requests.get(url=link,headers=headers).content filePath = dirName+\u0026#39;/\u0026#39;+title with open(filePath,\u0026#39;wb\u0026#39;) as fp: fp.write(data) print(title,\u0026#39;下载保存成功！\u0026#39;) Cookie 什么是cookie？\n","keywords":[""],"articleBody":" 简历模板下载拓展\nimport requests from lxml import etree import os headers = { 'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36', } #创建一个新的文件夹 dirName = 'jianli' if not os.path.exists(dirName): os.mkdir(dirName) #通用的url模板 url = 'https://sc.chinaz.com/jianli/free_%d.html' for page in range(1,11): if page == 1: new_url = 'https://sc.chinaz.com/jianli/free.html' else: new_url = format(url%page) response = requests.get(url=new_url,headers=headers) response.encoding = 'utf-8' page_text = response.text #数据解析：详情页url和简历名称 tree = etree.HTML(page_text) div_list = tree.xpath('//*[@id=\"container\"]/div') #局部解析 for div in div_list: detail_url = 'https:'+div.xpath('./a/@href')[0] title = div.xpath('./p/a/text()')[0]+'.rar' # print(title,detail_url) #对详情页的url发起请求，解析出简历的下载地址 detail_page_text = requests.get(url=detail_url,headers=headers).text #数据解析：解析下载地址 detail_tree = etree.HTML(detail_page_text) li_list = detail_tree.xpath('//*[@id=\"down\"]/div[2]/ul/li') down_list = [] #存储不同的12个下载地址 for li in li_list: download_link = li.xpath('./a/@href')[0] down_list.append(download_link) #随机选择一个下载地址进行简历模板的下载 import random #从列表中随机选出一个下载地址 link = random.choice(down_list) #对下载地址进行请求发送，下载简历模板的压缩包 data = requests.get(url=link,headers=headers).content filePath = dirName+'/'+title with open(filePath,'wb') as fp: fp.write(data) print(title,'下载保存成功！') Cookie 什么是cookie？\ncookie的本质就是一组数据（键值对的形式存在） 是由服务器创建，返回给客户端，最终会保存在客户端浏览器中。 如果客户端保存了cookie，则下次再次访问该服务器，就会携带cookie进行网络访问。 典型的案例：网站的免密登录 爬取雪球网中的咨询数据\nurl：https://xueqiu.com/，需求就是爬取热帖内容\n经过分析发现帖子的内容是通过ajax动态加载出来的，因此通过抓包工具，定位到ajax请求的数据包，从数据包中提取：\nurl：https://xueqiu.com/statuses/hot/listV2.json?since_id=-1\u0026max_id=311519\u0026size=15 请求方式：get 请求参数：拼接在了url后面 import requests import os headers = { 'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36', } url = 'https://xueqiu.com/statuses/hot/listV2.json' param = { \"since_id\": \"-1\", \"max_id\": \"311519\", \"size\": \"15\", } response = requests.get(url=url,headers=headers,params=param) data = response.json() print(data) #发现没有拿到我们想要的数据 分析why？\n切记：只要爬虫拿不到你想要的数据，唯一的原因是爬虫程序模拟浏览器的力度不够！一般来讲，模拟的力度重点放置在请求头中！ 上述案例，只需要在请求头headers中添加cookie即可！ 爬虫中cookie的处理方式（两种方式）：\n手动处理：将抓包工具中的cookie赋值到headers中即可\n缺点： 编写麻烦 cookie通常都会存在有效时长 cookie中可能会存在实时变化的局部数据 自动处理\n基于session对象实现自动处理cookie。\n1.创建一个空白的session对象。 2.需要使用session对象发起请求，请求的目的是为了捕获cookie 注意：如果session对象在发请求的过程中，服务器端产生了cookie，则cookie会自动存储在session对象中。 3.使用携带cookie的session对象，对目的网址发起请求，就可以实现携带cookie的请求发送，从而获取想要的数据。 注意：session对象至少需要发起两次请求\n第一次请求的目的是为了捕获存储cookie到session对象 后次的请求，就是携带cookie发起的请求了 import requests #1.创建一个空白的session对象 session = requests.Session() headers = { 'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36', } main_url = 'https://xueqiu.com/' #2.使用session发起的请求，目的是为了捕获到cookie，且将其存储到session对象中 session.get(url=main_url,headers=headers) url = 'https://xueqiu.com/statuses/hot/listV2.json' param = { \"since_id\": \"-1\", \"max_id\": \"311519\", \"size\": \"15\", } #3.就是使用携带了cookie的session对象发起的请求（就是携带者cookie发起的请求） response = session.get(url=url,headers=headers,params=param) data = response.json() print(data) 代理 什么是代理 代理服务器 代理服务器的作用 就是用来转发请求和响应 在爬虫中为何需要使用代理？\n有些时候，需要对网站服务器发起高频的请求，网站的服务器会检测到这样的异常现象，则会讲请求对应机器的ip地址加入黑名单，则该ip再次发起的请求，网站服务器就不在受理，则我们就无法再次爬取该网站的数据。 使用代理后，网站服务器接收到的请求，最终是由代理服务器发起，网站服务器通过请求获取的ip就是代理服务器的ip，并不是我们客户端本身的ip。 代理的匿名度\n透明：网站的服务器知道你使用了代理，也知道你的真实ip 匿名：网站服务器知道你使用了代理，但是无法获知你真实的ip 高匿：网站服务器不知道你使用了代理，也不知道你的真实ip（推荐） 代理的类型（重要）\nhttp：该类型的代理服务器只可以转发http协议的请求 https：可以转发https协议的请求 如何获取代理?\n代理精灵：http://http.zhiliandaili.cn/ 芝麻代理：https://jahttp.zhimaruanjian.com/（推荐，有新人福利） 如何使用代理？\n测试：访问如下网址，返回自己本机ip\nimport requests from lxml import etree headers = { 'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36', } url = 'https://www.sogou.com/web?query=ip' page_text = requests.get(url=url,headers=headers).text tree = etree.HTML(page_text) data = tree.xpath('//*[@id=\"ipsearchresult\"]/strong/text()')[0] print(data) 使用代理发起请求，查看是否可以返回代理服务器的ip\nimport requests from lxml import etree headers = { 'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36', } url = 'https://www.sogou.com/web?query=ip' #使用代理服务器发起请求 #proxies={'代理类型':'ip:port'} page_text = requests.get(url=url,headers=headers,proxies={'https':'42.57.150.150:4278'}).text tree = etree.HTML(page_text) data = tree.xpath('//*[@id=\"ipsearchresult\"]/strong/text()')[0] print(data) 深度测试：\n对快代理进行n次请求，直到本机无法访问快代理为止（证明本机ip被快代理封掉了）\n构建一个代理池（封装了很多代理ip和端口的容器），用于数据的批量爬取\nfrom bs4 import BeautifulSoup from lxml import etree import requests import time import random headers = { 'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36' } #构建一个代理池 proxy_url = 'http://webapi.http.zhimacangku.com/getip?num=15\u0026type=2\u0026pro=\u0026city=0\u0026yys=0\u0026port=1\u0026pack=213751\u0026ts=0\u0026ys=0\u0026cs=0\u0026lb=6\u0026sb=-\u0026pb=4\u0026mr=1\u0026regions=' json_data = requests.get(url=proxy_url,headers=headers).json() json_list = json_data['data'] proxy_list = [] #代理池,每次请求，可以随机从代理池中选择一个代理来用 for dic in json_list: ip = dic['ip'] port = dic['port'] n_dic = { 'https':ip+':'+str(port) # {'https':'111.1.1.1:1234'} } proxy_list.append(n_dic) #爬取多页 #1.创建一个通用的url(可以变换成任意页码的url) url = 'https://www.kuaidaili.com/free/inha/%d/' #2.通过循环以此生成不同页码的url for page in range(1,4): print('----------正在爬取第%d页的数据！-----------'%page) #format用来格式化字符串的（不可以修改url这个字符串本身） new_url = format(url%page) #循环发送每一页的请求 #注意：get方法是一个阻塞方法！ page_text = requests.get(url=new_url,headers=headers,proxies=random.choice(proxy_list)).text time.sleep(1) soup = BeautifulSoup(page_text,'lxml') trs = soup.select('tbody \u003e tr') for tr in trs: t1 = tr.findAll('td')[0] t2 = tr.findAll('td')[1] ip = t1.string port = t2.string print(ip,port) 验证码 图鉴平台：http://www.ttshitu.com/ （推荐）\n超级鹰：https://www.chaojiying.com/about.html\n使用图鉴识别古诗文网登录中的验证码\n古诗文网：https://so.gushiwen.cn/user/login.aspx?from=http://so.gushiwen.cn/user/collect.aspx\n使用流程：\n注册登录图鉴平台\n登录后，点击开发文档，提取识别的源代码\n模块(tujian.py)的封装：\nimport base64 import json import requests # 一、图片文字类型(默认 3 数英混合)： # 1 : 纯数字 # 1001：纯数字2 # 2 : 纯英文 # 1002：纯英文2 # 3 : 数英混合 # 1003：数英混合2 # 4 : 闪动GIF # 7 : 无感学习(独家) # 11 : 计算题 # 1005: 快速计算题 # 16 : 汉字 # 32 : 通用文字识别(证件、单据) # 66: 问答题 # 49 :recaptcha图片识别 # 二、图片旋转角度类型： # 29 : 旋转类型 # # 三、图片坐标点选类型： # 19 : 1个坐标 # 20 : 3个坐标 # 21 : 3 ~ 5个坐标 # 22 : 5 ~ 8个坐标 # 27 : 1 ~ 4个坐标 # 48 : 轨迹类型 # # 四、缺口识别 # 18 : 缺口识别（需要2张图 一张目标图一张缺口图） # 33 : 单缺口识别（返回X轴坐标 只需要1张图） # 五、拼图识别 # 53：拼图识别 #函数实现忽略 def base64_api(uname, pwd, img, typeid): with open(img, 'rb') as f: base64_data = base64.b64encode(f.read()) b64 = base64_data.decode() data = {\"username\": uname, \"password\": pwd, \"typeid\": typeid, \"image\": b64} result = json.loads(requests.post(\"http://api.ttshitu.com/predict\", json=data).text) if result['success']: return result[\"data\"][\"result\"] else: return result[\"message\"] return \"\" def getImgCodeText(imgPath,imgType):#直接返回验证码内容 #imgPath：验证码图片地址 #imgType：验证码图片类型 result = base64_api(uname='bb328410948', pwd='bb328410948', img=imgPath, typeid=imgType) return result 验证码图片识别操作\nfrom lxml import etree import requests import tujian headers = { 'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36' } #将验证码图片请求后保存到本地 login_url = 'https://so.gushiwen.cn/user/login.aspx?from=http://so.gushiwen.cn/user/collect.aspx' page_text = requests.get(url=login_url,headers=headers).text tree = etree.HTML(page_text) img_src = 'https://so.gushiwen.cn'+tree.xpath('//*[@id=\"imgCode\"]/@src')[0] code_data = requests.get(url=img_src,headers=headers).content with open('./code.jpg','wb') as fp: fp.write(code_data) #识别验证码图片内容 result = tujian.getImgCodeText('./code.jpg',3) print(result) 模拟登录 古诗文网\n在抓包工具里定位点击登录按钮后对应的数据包：\n只要数据包的请求参数中包含用户名，密码和验证码则该数据包就是我们要定位的\n首次模拟登录操作：\nfrom lxml import etree import requests import tujian headers = { 'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36' } #将验证码图片请求后保存到本地 login_url = 'https://so.gushiwen.cn/user/login.aspx?from=http://so.gushiwen.cn/user/collect.aspx' page_text = requests.get(url=login_url,headers=headers).text tree = etree.HTML(page_text) img_src = 'https://so.gushiwen.cn'+tree.xpath('//*[@id=\"imgCode\"]/@src')[0] code_data = requests.get(url=img_src,headers=headers).content with open('./code.jpg','wb') as fp: fp.write(code_data) #识别验证码图片内容 result = tujian.getImgCodeText('./code.jpg',3) print(result) #模拟登录 url = 'https://so.gushiwen.cn/user/login.aspx?from=http%3a%2f%2fso.gushiwen.cn%2fuser%2fcollect.aspx' data = { \"__VIEWSTATE\": \"opfVI7oolwkr7MLRVzsNSMASqLRUuO1dg5ZP5EIRa4FyM+mOYKEs6KWEKQKaba2ulLoZQIaLFiKK4mr5K3ci1v8ua28wtcRtabKWjOtJtU/i2etH+zSduegTMcg=\", \"__VIEWSTATEGENERATOR\": \"C93BE1AE\", \"from\": \"http://so.gushiwen.cn/user/collect.aspx\", \"email\": \"15027900535\", \"pwd\": \"bobo@15027900535\", \"code\":result , \"denglu\": \"登录\" } #获取了登录成功后的页面源码数据 login_page_text = requests.post(url=url,headers=headers,data=data).text with open('wushiwen.html','w') as fp: fp.write(login_page_text) 查看gushiwen.html发现，没有登录成功，原因：\n验证码不对（否定）\n没有携带cookie\n出现了动态变化的请求参数\n如何获取动态变化的请求参数 基于抓包工具进行全局搜索，发现该参数值被隐藏在了登录页面的页面源码中 from lxml import etree import requests import tujian headers = { 'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36' } #创建session对象 session = requests.Session() #将验证码图片请求后保存到本地 login_url = 'https://so.gushiwen.cn/user/login.aspx?from=http://so.gushiwen.cn/user/collect.aspx' page_text = session.get(url=login_url,headers=headers).text tree = etree.HTML(page_text) img_src = 'https://so.gushiwen.cn'+tree.xpath('//*[@id=\"imgCode\"]/@src')[0] code_data = session.get(url=img_src,headers=headers).content with open('./code.jpg','wb') as fp: fp.write(code_data) #解析出动态变化的请求参数 __VIEWSTATE = tree.xpath('//*[@id=\"__VIEWSTATE\"]/@value')[0] #识别验证码图片内容 result = tujian.getImgCodeText('./code.jpg',3) print(result) #模拟登录 url = 'https://so.gushiwen.cn/user/login.aspx?from=http%3a%2f%2fso.gushiwen.cn%2fuser%2fcollect.aspx' data = { \"__VIEWSTATE\": __VIEWSTATE, \"__VIEWSTATEGENERATOR\": \"C93BE1AE\", \"from\": \"http://so.gushiwen.cn/user/collect.aspx\", \"email\": \"15027900535\", \"pwd\": \"bobo@15027900535\", \"code\":result , \"denglu\": \"登录\" } #获取了登录成功后的页面源码数据 login_page_text = session.post(url=url,headers=headers,data=data).text with open('wushiwen.html','w') as fp: fp.write(login_page_text) 防盗链 现在很多网站启用了防盗链反爬，防止服务器上的资源被人恶意盗取。什么是防盗链呢？\n以图片为例，访问图片要从他的网站访问才可以，否则直接访问图片地址得不到图片 练习：抓取微博图片，url：http://blog.sina.com.cn/lm/pic/，将页面中某一组系列详情页的图片进行抓取保存，比如三里屯时尚女郎：http://blog.sina.com.cn/s/blog_01ebcb8a0102zi2o.html?tj=1\n注意：\n1.在解析图片地址的时候，定位src的属性值，返回的内容和开发工具Element中看到的不一样，通过network查看网页源码发现需要解析real_src的值。\n2.直接请求real_src请求到的图片不显示，加上Refere请求头即可\n哪里找Refere：抓包工具定位到某一张图片数据包，在其requests headers中获取 import requests from lxml import etree headers = { 'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36', \"Referer\": \"http://blog.sina.com.cn/\", } url = 'http://blog.sina.com.cn/s/blog_01ebcb8a0102zi2o.html?tj=1' page_text = requests.get(url,headers=headers).text tree = etree.HTML(page_text) img_src = tree.xpath('//*[@id=\"sina_keyword_ad_area2\"]/div/a/img/@real_src') for src in img_src: data = requests.get(src,headers=headers).content with open('./123.jpg','wb') as fp: fp.write(data) # break 图片懒加载(作业) url：https://sc.chinaz.com/tupian/meinvtupian.html 爬取上述链接中所有的图片数据 图片懒加载： 主要是应用在展示图片的网页中的一种技术，该技术是指当网页刷新后，先加载局部的几张图片数据即可，随着用户滑动滚轮，当图片被显示在浏览器的可视化区域范围的话，在动态将其图片请求加载出来即可。（图片数据是动态加载出来）。 如何实现图片懒加载/动态加载？ 使用img标签的伪属性（指的是自定义的一种属性）。在网页中，为了防止图片马上加载出来，则在img标签中可以使用一种伪属性来存储图片的链接，而不是使用真正的src属性值来存储图片链接。（图片链接一旦给了src属性，则图片会被立即加载出来）。只有当图片被滑动到浏览器可视化区域范围的时候，在通过js将img的伪属性修改为真正的src属性，则图片就会被加载出来。 如何爬取图片懒加载的图片数据？ 只需要在解析图片的时候，定位伪属性（src2）的属性值即可。 ","wordCount":"4409","inLanguage":"en","datePublished":"2023-02-10T14:04:30+08:00","dateModified":"2023-02-10T14:04:30+08:00","author":[{"@type":"Person","name":"Felix"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://canw0916.github.io/en/posts/tech/requests%E9%AB%98%E7%BA%A7/"},"publisher":{"@type":"Organization","name":"Felix's Blog","logo":{"@type":"ImageObject","url":"https://canw0916.github.io/img/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><script async src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script><header class=header><nav class=nav><div class=logo><a href=https://canw0916.github.io/en/ accesskey=h title="Felix's Blog (Alt + H)"><img src=https://canw0916.github.io/img/android-chrome-512x512.png alt=logo aria-label=logo height=35>Felix's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://canw0916.github.io/en/search title="🔍 搜索 (Alt + /)" accesskey=/><span>🔍 搜索</span></a></li><li><a href=https://canw0916.github.io/en/ title="🏠 主页"><span>🏠 主页</span></a></li><li><a href=https://canw0916.github.io/en/posts title="📚 文章"><span>📚 文章</span></a></li><li><a href=https://canw0916.github.io/en/tags title="💡 标签"><span>💡 标签</span></a></li><li><a href=https://canw0916.github.io/en/archives/ title="⏱️ 时间轴"><span>⏱️ 时间轴</span></a></li><li><a href=https://canw0916.github.io/en/about title="👦 关于"><span>👦 关于</span></a></li><li><a href=https://canw0916.github.io/en/links title="😺 友链"><span>😺 友链</span></a></li></ul></nav></header><main class="main page"><article class=post-single><div id=single-content><header class=post-header><div class=breadcrumbs><a href=https://canw0916.github.io/en/>🏠主页</a>&nbsp;»&nbsp;<a href=https://canw0916.github.io/en/posts/>📚文章</a>&nbsp;»&nbsp;<a href=https://canw0916.github.io/en/posts/tech/>🚀 技术</a></div><h1 class=post-title>Requests高级</h1><div class=post-meta>创建:2023-02-10|字数:4409字|时长: 9分钟|
作者:Felix
&nbsp;&nbsp;标签: &nbsp;<ul class=post-tags-meta><a href=https://canw0916.github.io/en/tags/python/>Python</a></ul><span id=busuanzi_container_page_pv>&nbsp;| 访问: <span id=busuanzi_value_page_pv></span></span></div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>文章目录</span></summary><div class=inner><ul><li><a href=#cookie aria-label=Cookie>Cookie</a></li><li><a href=#%e4%bb%a3%e7%90%86 aria-label=代理>代理</a></li><li><a href=#%e9%aa%8c%e8%af%81%e7%a0%81 aria-label=验证码>验证码</a></li><li><a href=#%e6%a8%a1%e6%8b%9f%e7%99%bb%e5%bd%95 aria-label=模拟登录>模拟登录</a></li><li><a href=#%e9%98%b2%e7%9b%97%e9%93%be aria-label=防盗链>防盗链</a></li><li><a href=#%e5%9b%be%e7%89%87%e6%87%92%e5%8a%a0%e8%bd%bd%e4%bd%9c%e4%b8%9a aria-label=图片懒加载(作业)>图片懒加载(作业)</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><ul><li><p>简历模板下载拓展</p></li><li><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>  <span class=kn>from</span> <span class=nn>lxml</span> <span class=kn>import</span> <span class=n>etree</span>
</span></span><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl>  <span class=n>headers</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;User-Agent&#39;</span><span class=p>:</span><span class=s1>&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=c1>#创建一个新的文件夹</span>
</span></span><span class=line><span class=cl>  <span class=n>dirName</span> <span class=o>=</span> <span class=s1>&#39;jianli&#39;</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>dirName</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=n>os</span><span class=o>.</span><span class=n>mkdir</span><span class=p>(</span><span class=n>dirName</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1>#通用的url模板</span>
</span></span><span class=line><span class=cl>  <span class=n>url</span> <span class=o>=</span> <span class=s1>&#39;https://sc.chinaz.com/jianli/free_</span><span class=si>%d</span><span class=s1>.html&#39;</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>page</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>11</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>if</span> <span class=n>page</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=n>new_url</span> <span class=o>=</span> <span class=s1>&#39;https://sc.chinaz.com/jianli/free.html&#39;</span>
</span></span><span class=line><span class=cl>      <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=n>new_url</span> <span class=o>=</span> <span class=nb>format</span><span class=p>(</span><span class=n>url</span><span class=o>%</span><span class=n>page</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>response</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>new_url</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>response</span><span class=o>.</span><span class=n>encoding</span> <span class=o>=</span> <span class=s1>&#39;utf-8&#39;</span>
</span></span><span class=line><span class=cl>      <span class=n>page_text</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>      <span class=c1>#数据解析：详情页url和简历名称</span>
</span></span><span class=line><span class=cl>      <span class=n>tree</span> <span class=o>=</span> <span class=n>etree</span><span class=o>.</span><span class=n>HTML</span><span class=p>(</span><span class=n>page_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>div_list</span> <span class=o>=</span> <span class=n>tree</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;//*[@id=&#34;container&#34;]/div&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=c1>#局部解析</span>
</span></span><span class=line><span class=cl>      <span class=k>for</span> <span class=n>div</span> <span class=ow>in</span> <span class=n>div_list</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=n>detail_url</span> <span class=o>=</span> <span class=s1>&#39;https:&#39;</span><span class=o>+</span><span class=n>div</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;./a/@href&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>          <span class=n>title</span> <span class=o>=</span> <span class=n>div</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;./p/a/text()&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span><span class=o>+</span><span class=s1>&#39;.rar&#39;</span>
</span></span><span class=line><span class=cl>          <span class=c1># print(title,detail_url)</span>
</span></span><span class=line><span class=cl>          <span class=c1>#对详情页的url发起请求，解析出简历的下载地址</span>
</span></span><span class=line><span class=cl>          <span class=n>detail_page_text</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>detail_url</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>)</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>          <span class=c1>#数据解析：解析下载地址</span>
</span></span><span class=line><span class=cl>          <span class=n>detail_tree</span> <span class=o>=</span> <span class=n>etree</span><span class=o>.</span><span class=n>HTML</span><span class=p>(</span><span class=n>detail_page_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>          <span class=n>li_list</span> <span class=o>=</span> <span class=n>detail_tree</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;//*[@id=&#34;down&#34;]/div[2]/ul/li&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>          <span class=n>down_list</span> <span class=o>=</span> <span class=p>[]</span> <span class=c1>#存储不同的12个下载地址</span>
</span></span><span class=line><span class=cl>          <span class=k>for</span> <span class=n>li</span> <span class=ow>in</span> <span class=n>li_list</span><span class=p>:</span>
</span></span><span class=line><span class=cl>              <span class=n>download_link</span> <span class=o>=</span> <span class=n>li</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;./a/@href&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>              <span class=n>down_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>download_link</span><span class=p>)</span>
</span></span><span class=line><span class=cl>          <span class=c1>#随机选择一个下载地址进行简历模板的下载</span>
</span></span><span class=line><span class=cl>          <span class=kn>import</span> <span class=nn>random</span>
</span></span><span class=line><span class=cl>          <span class=c1>#从列表中随机选出一个下载地址</span>
</span></span><span class=line><span class=cl>          <span class=n>link</span> <span class=o>=</span> <span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>down_list</span><span class=p>)</span>
</span></span><span class=line><span class=cl>          <span class=c1>#对下载地址进行请求发送，下载简历模板的压缩包</span>
</span></span><span class=line><span class=cl>          <span class=n>data</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>link</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>)</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>          <span class=n>filePath</span> <span class=o>=</span> <span class=n>dirName</span><span class=o>+</span><span class=s1>&#39;/&#39;</span><span class=o>+</span><span class=n>title</span>
</span></span><span class=line><span class=cl>          <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>filePath</span><span class=p>,</span><span class=s1>&#39;wb&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>fp</span><span class=p>:</span>
</span></span><span class=line><span class=cl>              <span class=n>fp</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>          <span class=nb>print</span><span class=p>(</span><span class=n>title</span><span class=p>,</span><span class=s1>&#39;下载保存成功！&#39;</span><span class=p>)</span>
</span></span></code></pre></div></li></ul><h3 id=cookie>Cookie<a hidden class=anchor aria-hidden=true href=#cookie>#</a></h3><ul><li><p>什么是cookie？</p><ul><li>cookie的本质就是一组数据（键值对的形式存在）</li><li>是由服务器创建，返回给客户端，最终会保存在客户端浏览器中。</li><li>如果客户端保存了cookie，则下次再次访问该服务器，就会携带cookie进行网络访问。<ul><li>典型的案例：网站的免密登录</li></ul></li></ul></li><li><p>爬取雪球网中的咨询数据</p><ul><li><p>url：https://xueqiu.com/，需求就是爬取热帖内容</p></li><li><p>经过分析发现帖子的内容是通过ajax动态加载出来的，因此通过抓包工具，定位到ajax请求的数据包，从数据包中提取：</p><ul><li>url：https://xueqiu.com/statuses/hot/listV2.json?since_id=-1&amp;max_id=311519&amp;size=15</li><li>请求方式：get</li><li>请求参数：拼接在了url后面</li></ul></li><li><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl>  <span class=n>headers</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;User-Agent&#39;</span><span class=p>:</span><span class=s1>&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=n>url</span> <span class=o>=</span> <span class=s1>&#39;https://xueqiu.com/statuses/hot/listV2.json&#39;</span>
</span></span><span class=line><span class=cl>  <span class=n>param</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;since_id&#34;</span><span class=p>:</span> <span class=s2>&#34;-1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;max_id&#34;</span><span class=p>:</span> <span class=s2>&#34;311519&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;size&#34;</span><span class=p>:</span> <span class=s2>&#34;15&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=n>response</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>url</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>,</span><span class=n>params</span><span class=o>=</span><span class=n>param</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>data</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>json</span><span class=p>()</span>
</span></span><span class=line><span class=cl>  <span class=nb>print</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1>#发现没有拿到我们想要的数据</span>
</span></span></code></pre></div></li><li><p>分析why？</p><ul><li>切记：只要爬虫拿不到你想要的数据，唯一的原因是爬虫程序模拟浏览器的力度不够！一般来讲，模拟的力度重点放置在请求头中！</li><li>上述案例，只需要在请求头headers中添加cookie即可！</li></ul></li><li><p>爬虫中cookie的处理方式（两种方式）：</p><ul><li><p>手动处理：将抓包工具中的cookie赋值到headers中即可</p><ul><li>缺点：<ul><li>编写麻烦</li><li>cookie通常都会存在有效时长</li><li>cookie中可能会存在实时变化的局部数据</li></ul></li></ul></li><li><p>自动处理</p><ul><li><p>基于session对象实现自动处理cookie。</p><ul><li>1.创建一个空白的session对象。</li><li>2.需要使用session对象发起请求，请求的目的是为了捕获cookie<ul><li>注意：如果session对象在发请求的过程中，服务器端产生了cookie，则cookie会自动存储在session对象中。</li></ul></li><li>3.使用携带cookie的session对象，对目的网址发起请求，就可以实现携带cookie的请求发送，从而获取想要的数据。</li></ul></li><li><p>注意：session对象至少需要发起两次请求</p><ul><li>第一次请求的目的是为了捕获存储cookie到session对象</li><li>后次的请求，就是携带cookie发起的请求了</li></ul></li><li><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>  <span class=c1>#1.创建一个空白的session对象</span>
</span></span><span class=line><span class=cl>  <span class=n>session</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>Session</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>headers</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;User-Agent&#39;</span><span class=p>:</span><span class=s1>&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=n>main_url</span> <span class=o>=</span> <span class=s1>&#39;https://xueqiu.com/&#39;</span>
</span></span><span class=line><span class=cl>  <span class=c1>#2.使用session发起的请求，目的是为了捕获到cookie，且将其存储到session对象中</span>
</span></span><span class=line><span class=cl>  <span class=n>session</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>main_url</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>url</span> <span class=o>=</span> <span class=s1>&#39;https://xueqiu.com/statuses/hot/listV2.json&#39;</span>
</span></span><span class=line><span class=cl>  <span class=n>param</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;since_id&#34;</span><span class=p>:</span> <span class=s2>&#34;-1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;max_id&#34;</span><span class=p>:</span> <span class=s2>&#34;311519&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;size&#34;</span><span class=p>:</span> <span class=s2>&#34;15&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=c1>#3.就是使用携带了cookie的session对象发起的请求（就是携带者cookie发起的请求）</span>
</span></span><span class=line><span class=cl>  <span class=n>response</span> <span class=o>=</span> <span class=n>session</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>url</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>,</span><span class=n>params</span><span class=o>=</span><span class=n>param</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>data</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>json</span><span class=p>()</span>
</span></span><span class=line><span class=cl>  <span class=nb>print</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span></code></pre></div></li></ul></li></ul></li></ul></li></ul><h3 id=代理>代理<a hidden class=anchor aria-hidden=true href=#代理>#</a></h3><ul><li>什么是代理<ul><li>代理服务器</li></ul></li><li>代理服务器的作用<ul><li>就是用来转发请求和响应</li></ul></li></ul><p><img loading=lazy src=https://cdn.jsdelivr.net/gh/canw0916/picgo_imgs@main/blog/Snip20220124_45.png alt=Snip20220124_45></p><ul><li><p>在爬虫中为何需要使用代理？</p><ul><li>有些时候，需要对网站服务器发起高频的请求，网站的服务器会检测到这样的异常现象，则会讲请求对应机器的ip地址加入黑名单，则该ip再次发起的请求，网站服务器就不在受理，则我们就无法再次爬取该网站的数据。</li><li>使用代理后，网站服务器接收到的请求，最终是由代理服务器发起，网站服务器通过请求获取的ip就是代理服务器的ip，并不是我们客户端本身的ip。</li></ul></li><li><p>代理的匿名度</p><ul><li>透明：网站的服务器知道你使用了代理，也知道你的真实ip</li><li>匿名：网站服务器知道你使用了代理，但是无法获知你真实的ip</li><li>高匿：网站服务器不知道你使用了代理，也不知道你的真实ip（推荐）</li></ul></li><li><p>代理的类型（重要）</p><ul><li>http：该类型的代理服务器只可以转发http协议的请求</li><li>https：可以转发https协议的请求</li></ul></li><li><p>如何获取代理?</p><ul><li>代理精灵：http://http.zhiliandaili.cn/</li><li>芝麻代理：https://jahttp.zhimaruanjian.com/（推荐，有新人福利）</li></ul></li><li><p>如何使用代理？</p><ul><li><p>测试：访问如下网址，返回自己本机ip</p></li><li><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>  <span class=kn>from</span> <span class=nn>lxml</span> <span class=kn>import</span> <span class=n>etree</span>
</span></span><span class=line><span class=cl>  <span class=n>headers</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;User-Agent&#39;</span><span class=p>:</span><span class=s1>&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=n>url</span> <span class=o>=</span> <span class=s1>&#39;https://www.sogou.com/web?query=ip&#39;</span>
</span></span><span class=line><span class=cl>  <span class=n>page_text</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>url</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>)</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>  <span class=n>tree</span> <span class=o>=</span> <span class=n>etree</span><span class=o>.</span><span class=n>HTML</span><span class=p>(</span><span class=n>page_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>data</span> <span class=o>=</span> <span class=n>tree</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;//*[@id=&#34;ipsearchresult&#34;]/strong/text()&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=nb>print</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span></code></pre></div></li><li><p>使用代理发起请求，查看是否可以返回代理服务器的ip</p></li><li><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>  <span class=kn>from</span> <span class=nn>lxml</span> <span class=kn>import</span> <span class=n>etree</span>
</span></span><span class=line><span class=cl>  <span class=n>headers</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;User-Agent&#39;</span><span class=p>:</span><span class=s1>&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.80 Safari/537.36&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=n>url</span> <span class=o>=</span> <span class=s1>&#39;https://www.sogou.com/web?query=ip&#39;</span>
</span></span><span class=line><span class=cl>  <span class=c1>#使用代理服务器发起请求</span>
</span></span><span class=line><span class=cl>  <span class=c1>#proxies={&#39;代理类型&#39;:&#39;ip:port&#39;}</span>
</span></span><span class=line><span class=cl>  <span class=n>page_text</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>url</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>,</span><span class=n>proxies</span><span class=o>=</span><span class=p>{</span><span class=s1>&#39;https&#39;</span><span class=p>:</span><span class=s1>&#39;42.57.150.150:4278&#39;</span><span class=p>})</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>  <span class=n>tree</span> <span class=o>=</span> <span class=n>etree</span><span class=o>.</span><span class=n>HTML</span><span class=p>(</span><span class=n>page_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>data</span> <span class=o>=</span> <span class=n>tree</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;//*[@id=&#34;ipsearchresult&#34;]/strong/text()&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=nb>print</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span></code></pre></div></li><li><p>深度测试：</p><ul><li><p>对快代理进行n次请求，直到本机无法访问快代理为止（证明本机ip被快代理封掉了）</p></li><li><p>构建一个代理池（封装了很多代理ip和端口的容器），用于数据的批量爬取</p></li><li><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=kn>from</span> <span class=nn>bs4</span> <span class=kn>import</span> <span class=n>BeautifulSoup</span>
</span></span><span class=line><span class=cl>  <span class=kn>from</span> <span class=nn>lxml</span> <span class=kn>import</span> <span class=n>etree</span>
</span></span><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>random</span>
</span></span><span class=line><span class=cl>  <span class=n>headers</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;User-Agent&#39;</span><span class=p>:</span><span class=s1>&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36&#39;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=c1>#构建一个代理池</span>
</span></span><span class=line><span class=cl>  <span class=n>proxy_url</span> <span class=o>=</span> <span class=s1>&#39;http://webapi.http.zhimacangku.com/getip?num=15&amp;type=2&amp;pro=&amp;city=0&amp;yys=0&amp;port=1&amp;pack=213751&amp;ts=0&amp;ys=0&amp;cs=0&amp;lb=6&amp;sb=-&amp;pb=4&amp;mr=1&amp;regions=&#39;</span>
</span></span><span class=line><span class=cl>  <span class=n>json_data</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>proxy_url</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>)</span><span class=o>.</span><span class=n>json</span><span class=p>()</span>
</span></span><span class=line><span class=cl>  <span class=n>json_list</span> <span class=o>=</span> <span class=n>json_data</span><span class=p>[</span><span class=s1>&#39;data&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=n>proxy_list</span> <span class=o>=</span> <span class=p>[]</span> <span class=c1>#代理池,每次请求，可以随机从代理池中选择一个代理来用</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>dic</span> <span class=ow>in</span> <span class=n>json_list</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>ip</span> <span class=o>=</span> <span class=n>dic</span><span class=p>[</span><span class=s1>&#39;ip&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>      <span class=n>port</span> <span class=o>=</span> <span class=n>dic</span><span class=p>[</span><span class=s1>&#39;port&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>      <span class=n>n_dic</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;https&#39;</span><span class=p>:</span><span class=n>ip</span><span class=o>+</span><span class=s1>&#39;:&#39;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=n>port</span><span class=p>)</span> <span class=c1># {&#39;https&#39;:&#39;111.1.1.1:1234&#39;}</span>
</span></span><span class=line><span class=cl>      <span class=p>}</span>
</span></span><span class=line><span class=cl>      <span class=n>proxy_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>n_dic</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1>#爬取多页</span>
</span></span><span class=line><span class=cl>  <span class=c1>#1.创建一个通用的url(可以变换成任意页码的url)</span>
</span></span><span class=line><span class=cl>  <span class=n>url</span> <span class=o>=</span> <span class=s1>&#39;https://www.kuaidaili.com/free/inha/</span><span class=si>%d</span><span class=s1>/&#39;</span>
</span></span><span class=line><span class=cl>  <span class=c1>#2.通过循环以此生成不同页码的url</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>page</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span><span class=mi>4</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;----------正在爬取第</span><span class=si>%d</span><span class=s1>页的数据！-----------&#39;</span><span class=o>%</span><span class=n>page</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=c1>#format用来格式化字符串的（不可以修改url这个字符串本身）</span>
</span></span><span class=line><span class=cl>      <span class=n>new_url</span> <span class=o>=</span> <span class=nb>format</span><span class=p>(</span><span class=n>url</span><span class=o>%</span><span class=n>page</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=c1>#循环发送每一页的请求</span>
</span></span><span class=line><span class=cl>      <span class=c1>#注意：get方法是一个阻塞方法！</span>
</span></span><span class=line><span class=cl>      <span class=n>page_text</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>new_url</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>,</span><span class=n>proxies</span><span class=o>=</span><span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>proxy_list</span><span class=p>))</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>      <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>soup</span> <span class=o>=</span> <span class=n>BeautifulSoup</span><span class=p>(</span><span class=n>page_text</span><span class=p>,</span><span class=s1>&#39;lxml&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>trs</span> <span class=o>=</span> <span class=n>soup</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=s1>&#39;tbody &gt; tr&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=k>for</span> <span class=n>tr</span> <span class=ow>in</span> <span class=n>trs</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=n>t1</span> <span class=o>=</span> <span class=n>tr</span><span class=o>.</span><span class=n>findAll</span><span class=p>(</span><span class=s1>&#39;td&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>          <span class=n>t2</span> <span class=o>=</span> <span class=n>tr</span><span class=o>.</span><span class=n>findAll</span><span class=p>(</span><span class=s1>&#39;td&#39;</span><span class=p>)[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>          <span class=n>ip</span> <span class=o>=</span> <span class=n>t1</span><span class=o>.</span><span class=n>string</span>
</span></span><span class=line><span class=cl>          <span class=n>port</span> <span class=o>=</span> <span class=n>t2</span><span class=o>.</span><span class=n>string</span>
</span></span><span class=line><span class=cl>          <span class=nb>print</span><span class=p>(</span><span class=n>ip</span><span class=p>,</span><span class=n>port</span><span class=p>)</span>
</span></span></code></pre></div></li></ul></li></ul></li></ul><h3 id=验证码>验证码<a hidden class=anchor aria-hidden=true href=#验证码>#</a></h3><ul><li><p>图鉴平台：http://www.ttshitu.com/ （推荐）</p></li><li><p>超级鹰：https://www.chaojiying.com/about.html</p></li><li><p>使用图鉴识别古诗文网登录中的验证码</p><ul><li><p>古诗文网：https://so.gushiwen.cn/user/login.aspx?from=http://so.gushiwen.cn/user/collect.aspx</p></li><li><p>使用流程：</p><ul><li><p>注册登录图鉴平台</p></li><li><p>登录后，点击开发文档，提取识别的源代码</p></li><li><p>模块(tujian.py)的封装：</p></li><li><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>base64</span>
</span></span><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>  <span class=c1># 一、图片文字类型(默认 3 数英混合)：</span>
</span></span><span class=line><span class=cl>  <span class=c1># 1 : 纯数字</span>
</span></span><span class=line><span class=cl>  <span class=c1># 1001：纯数字2</span>
</span></span><span class=line><span class=cl>  <span class=c1># 2 : 纯英文</span>
</span></span><span class=line><span class=cl>  <span class=c1># 1002：纯英文2</span>
</span></span><span class=line><span class=cl>  <span class=c1># 3 : 数英混合</span>
</span></span><span class=line><span class=cl>  <span class=c1># 1003：数英混合2</span>
</span></span><span class=line><span class=cl>  <span class=c1>#  4 : 闪动GIF</span>
</span></span><span class=line><span class=cl>  <span class=c1># 7 : 无感学习(独家)</span>
</span></span><span class=line><span class=cl>  <span class=c1># 11 : 计算题</span>
</span></span><span class=line><span class=cl>  <span class=c1># 1005:  快速计算题</span>
</span></span><span class=line><span class=cl>  <span class=c1># 16 : 汉字</span>
</span></span><span class=line><span class=cl>  <span class=c1># 32 : 通用文字识别(证件、单据)</span>
</span></span><span class=line><span class=cl>  <span class=c1># 66:  问答题</span>
</span></span><span class=line><span class=cl>  <span class=c1># 49 :recaptcha图片识别</span>
</span></span><span class=line><span class=cl>  <span class=c1># 二、图片旋转角度类型：</span>
</span></span><span class=line><span class=cl>  <span class=c1># 29 :  旋转类型</span>
</span></span><span class=line><span class=cl>  <span class=c1>#</span>
</span></span><span class=line><span class=cl>  <span class=c1># 三、图片坐标点选类型：</span>
</span></span><span class=line><span class=cl>  <span class=c1># 19 :  1个坐标</span>
</span></span><span class=line><span class=cl>  <span class=c1># 20 :  3个坐标</span>
</span></span><span class=line><span class=cl>  <span class=c1># 21 :  3 ~ 5个坐标</span>
</span></span><span class=line><span class=cl>  <span class=c1># 22 :  5 ~ 8个坐标</span>
</span></span><span class=line><span class=cl>  <span class=c1># 27 :  1 ~ 4个坐标</span>
</span></span><span class=line><span class=cl>  <span class=c1># 48 : 轨迹类型</span>
</span></span><span class=line><span class=cl>  <span class=c1>#</span>
</span></span><span class=line><span class=cl>  <span class=c1># 四、缺口识别</span>
</span></span><span class=line><span class=cl>  <span class=c1># 18 : 缺口识别（需要2张图 一张目标图一张缺口图）</span>
</span></span><span class=line><span class=cl>  <span class=c1># 33 : 单缺口识别（返回X轴坐标 只需要1张图）</span>
</span></span><span class=line><span class=cl>  <span class=c1># 五、拼图识别</span>
</span></span><span class=line><span class=cl>  <span class=c1># 53：拼图识别</span>
</span></span><span class=line><span class=cl>  <span class=c1>#函数实现忽略</span>
</span></span><span class=line><span class=cl>  <span class=k>def</span> <span class=nf>base64_api</span><span class=p>(</span><span class=n>uname</span><span class=p>,</span> <span class=n>pwd</span><span class=p>,</span> <span class=n>img</span><span class=p>,</span> <span class=n>typeid</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>img</span><span class=p>,</span> <span class=s1>&#39;rb&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=n>base64_data</span> <span class=o>=</span> <span class=n>base64</span><span class=o>.</span><span class=n>b64encode</span><span class=p>(</span><span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>())</span>
</span></span><span class=line><span class=cl>          <span class=n>b64</span> <span class=o>=</span> <span class=n>base64_data</span><span class=o>.</span><span class=n>decode</span><span class=p>()</span>
</span></span><span class=line><span class=cl>      <span class=n>data</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&#34;username&#34;</span><span class=p>:</span> <span class=n>uname</span><span class=p>,</span> <span class=s2>&#34;password&#34;</span><span class=p>:</span> <span class=n>pwd</span><span class=p>,</span> <span class=s2>&#34;typeid&#34;</span><span class=p>:</span> <span class=n>typeid</span><span class=p>,</span> <span class=s2>&#34;image&#34;</span><span class=p>:</span> <span class=n>b64</span><span class=p>}</span>
</span></span><span class=line><span class=cl>      <span class=n>result</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>requests</span><span class=o>.</span><span class=n>post</span><span class=p>(</span><span class=s2>&#34;http://api.ttshitu.com/predict&#34;</span><span class=p>,</span> <span class=n>json</span><span class=o>=</span><span class=n>data</span><span class=p>)</span><span class=o>.</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=k>if</span> <span class=n>result</span><span class=p>[</span><span class=s1>&#39;success&#39;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>          <span class=k>return</span> <span class=n>result</span><span class=p>[</span><span class=s2>&#34;data&#34;</span><span class=p>][</span><span class=s2>&#34;result&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>      <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=k>return</span> <span class=n>result</span><span class=p>[</span><span class=s2>&#34;message&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>      <span class=k>return</span> <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>def</span> <span class=nf>getImgCodeText</span><span class=p>(</span><span class=n>imgPath</span><span class=p>,</span><span class=n>imgType</span><span class=p>):</span><span class=c1>#直接返回验证码内容</span>
</span></span><span class=line><span class=cl>      <span class=c1>#imgPath：验证码图片地址</span>
</span></span><span class=line><span class=cl>      <span class=c1>#imgType：验证码图片类型</span>
</span></span><span class=line><span class=cl>      <span class=n>result</span> <span class=o>=</span> <span class=n>base64_api</span><span class=p>(</span><span class=n>uname</span><span class=o>=</span><span class=s1>&#39;bb328410948&#39;</span><span class=p>,</span> <span class=n>pwd</span><span class=o>=</span><span class=s1>&#39;bb328410948&#39;</span><span class=p>,</span> <span class=n>img</span><span class=o>=</span><span class=n>imgPath</span><span class=p>,</span> <span class=n>typeid</span><span class=o>=</span><span class=n>imgType</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=k>return</span> <span class=n>result</span>
</span></span></code></pre></div></li><li><p>验证码图片识别操作</p></li><li><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=kn>from</span> <span class=nn>lxml</span> <span class=kn>import</span> <span class=n>etree</span>
</span></span><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>tujian</span>
</span></span><span class=line><span class=cl>  <span class=n>headers</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;User-Agent&#39;</span><span class=p>:</span><span class=s1>&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36&#39;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=c1>#将验证码图片请求后保存到本地</span>
</span></span><span class=line><span class=cl>  <span class=n>login_url</span> <span class=o>=</span> <span class=s1>&#39;https://so.gushiwen.cn/user/login.aspx?from=http://so.gushiwen.cn/user/collect.aspx&#39;</span>
</span></span><span class=line><span class=cl>  <span class=n>page_text</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>login_url</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>)</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>  <span class=n>tree</span> <span class=o>=</span> <span class=n>etree</span><span class=o>.</span><span class=n>HTML</span><span class=p>(</span><span class=n>page_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>img_src</span> <span class=o>=</span> <span class=s1>&#39;https://so.gushiwen.cn&#39;</span><span class=o>+</span><span class=n>tree</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;//*[@id=&#34;imgCode&#34;]/@src&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=n>code_data</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>img_src</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>)</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>  <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;./code.jpg&#39;</span><span class=p>,</span><span class=s1>&#39;wb&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>fp</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>fp</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>code_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1>#识别验证码图片内容</span>
</span></span><span class=line><span class=cl>  <span class=n>result</span> <span class=o>=</span> <span class=n>tujian</span><span class=o>.</span><span class=n>getImgCodeText</span><span class=p>(</span><span class=s1>&#39;./code.jpg&#39;</span><span class=p>,</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span></span></code></pre></div></li></ul></li></ul></li></ul><h3 id=模拟登录>模拟登录<a hidden class=anchor aria-hidden=true href=#模拟登录>#</a></h3><ul><li><p>古诗文网</p></li><li><p>在抓包工具里定位点击登录按钮后对应的数据包：</p><ul><li><p>只要数据包的请求参数中包含用户名，密码和验证码则该数据包就是我们要定位的</p></li><li><p>首次模拟登录操作：</p></li><li><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=kn>from</span> <span class=nn>lxml</span> <span class=kn>import</span> <span class=n>etree</span>
</span></span><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>tujian</span>
</span></span><span class=line><span class=cl>  <span class=n>headers</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;User-Agent&#39;</span><span class=p>:</span><span class=s1>&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36&#39;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=c1>#将验证码图片请求后保存到本地</span>
</span></span><span class=line><span class=cl>  <span class=n>login_url</span> <span class=o>=</span> <span class=s1>&#39;https://so.gushiwen.cn/user/login.aspx?from=http://so.gushiwen.cn/user/collect.aspx&#39;</span>
</span></span><span class=line><span class=cl>  <span class=n>page_text</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>login_url</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>)</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>  <span class=n>tree</span> <span class=o>=</span> <span class=n>etree</span><span class=o>.</span><span class=n>HTML</span><span class=p>(</span><span class=n>page_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>img_src</span> <span class=o>=</span> <span class=s1>&#39;https://so.gushiwen.cn&#39;</span><span class=o>+</span><span class=n>tree</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;//*[@id=&#34;imgCode&#34;]/@src&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=n>code_data</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>img_src</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>)</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>  <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;./code.jpg&#39;</span><span class=p>,</span><span class=s1>&#39;wb&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>fp</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>fp</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>code_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1>#识别验证码图片内容</span>
</span></span><span class=line><span class=cl>  <span class=n>result</span> <span class=o>=</span> <span class=n>tujian</span><span class=o>.</span><span class=n>getImgCodeText</span><span class=p>(</span><span class=s1>&#39;./code.jpg&#39;</span><span class=p>,</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1>#模拟登录</span>
</span></span><span class=line><span class=cl>  <span class=n>url</span> <span class=o>=</span> <span class=s1>&#39;https://so.gushiwen.cn/user/login.aspx?from=http</span><span class=si>%3a%2f%2f</span><span class=s1>so.gushiwen.cn</span><span class=si>%2f</span><span class=s1>user</span><span class=si>%2f</span><span class=s1>collect.aspx&#39;</span>
</span></span><span class=line><span class=cl>  <span class=n>data</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;__VIEWSTATE&#34;</span><span class=p>:</span> <span class=s2>&#34;opfVI7oolwkr7MLRVzsNSMASqLRUuO1dg5ZP5EIRa4FyM+mOYKEs6KWEKQKaba2ulLoZQIaLFiKK4mr5K3ci1v8ua28wtcRtabKWjOtJtU/i2etH+zSduegTMcg=&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;__VIEWSTATEGENERATOR&#34;</span><span class=p>:</span> <span class=s2>&#34;C93BE1AE&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;from&#34;</span><span class=p>:</span> <span class=s2>&#34;http://so.gushiwen.cn/user/collect.aspx&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;email&#34;</span><span class=p>:</span> <span class=s2>&#34;15027900535&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;pwd&#34;</span><span class=p>:</span> <span class=s2>&#34;bobo@15027900535&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;code&#34;</span><span class=p>:</span><span class=n>result</span> <span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;denglu&#34;</span><span class=p>:</span> <span class=s2>&#34;登录&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=c1>#获取了登录成功后的页面源码数据</span>
</span></span><span class=line><span class=cl>  <span class=n>login_page_text</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>post</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>url</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>,</span><span class=n>data</span><span class=o>=</span><span class=n>data</span><span class=p>)</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>  <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;wushiwen.html&#39;</span><span class=p>,</span><span class=s1>&#39;w&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>fp</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>fp</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>login_page_text</span><span class=p>)</span>
</span></span></code></pre></div></li><li><p>查看gushiwen.html发现，没有登录成功，原因：</p><ul><li><p>验证码不对（否定）</p></li><li><p>没有携带cookie</p></li><li><p>出现了动态变化的请求参数</p><ul><li>如何获取动态变化的请求参数<ul><li>基于抓包工具进行全局搜索，发现该参数值被隐藏在了登录页面的页面源码中</li></ul></li></ul></li><li><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=kn>from</span> <span class=nn>lxml</span> <span class=kn>import</span> <span class=n>etree</span>
</span></span><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>tujian</span>
</span></span><span class=line><span class=cl>  <span class=n>headers</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;User-Agent&#39;</span><span class=p>:</span><span class=s1>&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36&#39;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=c1>#创建session对象</span>
</span></span><span class=line><span class=cl>  <span class=n>session</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>Session</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1>#将验证码图片请求后保存到本地</span>
</span></span><span class=line><span class=cl>  <span class=n>login_url</span> <span class=o>=</span> <span class=s1>&#39;https://so.gushiwen.cn/user/login.aspx?from=http://so.gushiwen.cn/user/collect.aspx&#39;</span>
</span></span><span class=line><span class=cl>  <span class=n>page_text</span> <span class=o>=</span> <span class=n>session</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>login_url</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>)</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>  <span class=n>tree</span> <span class=o>=</span> <span class=n>etree</span><span class=o>.</span><span class=n>HTML</span><span class=p>(</span><span class=n>page_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>img_src</span> <span class=o>=</span> <span class=s1>&#39;https://so.gushiwen.cn&#39;</span><span class=o>+</span><span class=n>tree</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;//*[@id=&#34;imgCode&#34;]/@src&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=n>code_data</span> <span class=o>=</span> <span class=n>session</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>img_src</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>)</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>  <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;./code.jpg&#39;</span><span class=p>,</span><span class=s1>&#39;wb&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>fp</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>fp</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>code_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1>#解析出动态变化的请求参数</span>
</span></span><span class=line><span class=cl>  <span class=n>__VIEWSTATE</span> <span class=o>=</span> <span class=n>tree</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;//*[@id=&#34;__VIEWSTATE&#34;]/@value&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1>#识别验证码图片内容</span>
</span></span><span class=line><span class=cl>  <span class=n>result</span> <span class=o>=</span> <span class=n>tujian</span><span class=o>.</span><span class=n>getImgCodeText</span><span class=p>(</span><span class=s1>&#39;./code.jpg&#39;</span><span class=p>,</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1>#模拟登录</span>
</span></span><span class=line><span class=cl>  <span class=n>url</span> <span class=o>=</span> <span class=s1>&#39;https://so.gushiwen.cn/user/login.aspx?from=http</span><span class=si>%3a%2f%2f</span><span class=s1>so.gushiwen.cn</span><span class=si>%2f</span><span class=s1>user</span><span class=si>%2f</span><span class=s1>collect.aspx&#39;</span>
</span></span><span class=line><span class=cl>  <span class=n>data</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;__VIEWSTATE&#34;</span><span class=p>:</span> <span class=n>__VIEWSTATE</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;__VIEWSTATEGENERATOR&#34;</span><span class=p>:</span> <span class=s2>&#34;C93BE1AE&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;from&#34;</span><span class=p>:</span> <span class=s2>&#34;http://so.gushiwen.cn/user/collect.aspx&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;email&#34;</span><span class=p>:</span> <span class=s2>&#34;15027900535&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;pwd&#34;</span><span class=p>:</span> <span class=s2>&#34;bobo@15027900535&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;code&#34;</span><span class=p>:</span><span class=n>result</span> <span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;denglu&#34;</span><span class=p>:</span> <span class=s2>&#34;登录&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=c1>#获取了登录成功后的页面源码数据</span>
</span></span><span class=line><span class=cl>  <span class=n>login_page_text</span> <span class=o>=</span> <span class=n>session</span><span class=o>.</span><span class=n>post</span><span class=p>(</span><span class=n>url</span><span class=o>=</span><span class=n>url</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>,</span><span class=n>data</span><span class=o>=</span><span class=n>data</span><span class=p>)</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>  <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;wushiwen.html&#39;</span><span class=p>,</span><span class=s1>&#39;w&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>fp</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>fp</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>login_page_text</span><span class=p>)</span>
</span></span></code></pre></div></li></ul></li></ul></li></ul><h3 id=防盗链>防盗链<a hidden class=anchor aria-hidden=true href=#防盗链>#</a></h3><ul><li><p>现在很多网站启用了防盗链反爬，防止服务器上的资源被人恶意盗取。什么是防盗链呢？</p><ul><li>以图片为例，访问图片要从他的网站访问才可以，否则直接访问图片地址得不到图片</li></ul></li><li><p>练习：抓取微博图片，url：http://blog.sina.com.cn/lm/pic/，将页面中某一组系列详情页的图片进行抓取保存，比如三里屯时尚女郎：http://blog.sina.com.cn/s/blog_01ebcb8a0102zi2o.html?tj=1</p><ul><li><p>注意：</p><ul><li><p>1.在解析图片地址的时候，定位src的属性值，返回的内容和开发工具Element中看到的不一样，通过network查看网页源码发现需要解析real_src的值。</p></li><li><p>2.直接请求real_src请求到的图片不显示，加上Refere请求头即可</p><ul><li>哪里找Refere：抓包工具定位到某一张图片数据包，在其requests headers中获取</li></ul></li><li><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>  <span class=kn>from</span> <span class=nn>lxml</span> <span class=kn>import</span> <span class=n>etree</span>
</span></span><span class=line><span class=cl>  <span class=n>headers</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;User-Agent&#39;</span><span class=p>:</span><span class=s1>&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;Referer&#34;</span><span class=p>:</span> <span class=s2>&#34;http://blog.sina.com.cn/&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=n>url</span> <span class=o>=</span> <span class=s1>&#39;http://blog.sina.com.cn/s/blog_01ebcb8a0102zi2o.html?tj=1&#39;</span>
</span></span><span class=line><span class=cl>  <span class=n>page_text</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>)</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>  <span class=n>tree</span> <span class=o>=</span> <span class=n>etree</span><span class=o>.</span><span class=n>HTML</span><span class=p>(</span><span class=n>page_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>img_src</span> <span class=o>=</span> <span class=n>tree</span><span class=o>.</span><span class=n>xpath</span><span class=p>(</span><span class=s1>&#39;//*[@id=&#34;sina_keyword_ad_area2&#34;]/div/a/img/@real_src&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>src</span> <span class=ow>in</span> <span class=n>img_src</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>data</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>src</span><span class=p>,</span><span class=n>headers</span><span class=o>=</span><span class=n>headers</span><span class=p>)</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>      <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;./123.jpg&#39;</span><span class=p>,</span><span class=s1>&#39;wb&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>fp</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=n>fp</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=c1># break</span>
</span></span></code></pre></div></li></ul></li></ul></li></ul><h3 id=图片懒加载作业>图片懒加载(作业)<a hidden class=anchor aria-hidden=true href=#图片懒加载作业>#</a></h3><ul><li>url：https://sc.chinaz.com/tupian/meinvtupian.html</li><li>爬取上述链接中所有的图片数据</li><li>图片懒加载：<ul><li>主要是应用在展示图片的网页中的一种技术，该技术是指当网页刷新后，先加载局部的几张图片数据即可，随着用户滑动滚轮，当图片被显示在浏览器的可视化区域范围的话，在动态将其图片请求加载出来即可。（图片数据是动态加载出来）。</li><li>如何实现图片懒加载/动态加载？<ul><li>使用img标签的伪属性（指的是自定义的一种属性）。在网页中，为了防止图片马上加载出来，则在img标签中可以使用一种伪属性来存储图片的链接，而不是使用真正的src属性值来存储图片链接。（图片链接一旦给了src属性，则图片会被立即加载出来）。只有当图片被滑动到浏览器可视化区域范围的时候，在通过js将img的伪属性修改为真正的src属性，则图片就会被加载出来。</li></ul></li></ul></li><li>如何爬取图片懒加载的图片数据？<ul><li>只需要在解析图片的时候，定位伪属性（src2）的属性值即可。</li></ul></li></ul></div><div class=post-reward><div style=padding:0;margin:0;width:100%;font-size:16px;text-align:center><div id=QR style=opacity:0><div id=wechat style=display:inline-block><a class=fancybox rel=group><img id=wechat_qr src=https://canw0916.github.io/img/wxPay.jpg alt=wechat_pay></a><p>微信</p></div><div id=alipay style=display:inline-block><a class=fancybox rel=group><img id=alipay_qr src=https://canw0916.github.io/img/aliPay.jpg alt=alipay></a><p>支付宝</p></div></div><button id=rewardButton onclick='var qr=document.getElementById("QR");qr.style.opacity==="0"?qr.style.opacity="1":qr.style.opacity="0"'>
<span>🧧 鼓励</span></button></div></div><footer class=post-footer><nav class=paginav><a class=prev href=https://canw0916.github.io/en/posts/tech/%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB/><span class=title>« 上一页</span><br><span>异步爬虫</span>
</a><a class=next href=https://canw0916.github.io/en/posts/tech/%E7%88%AC%E8%99%AB%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90/><span class=title>下一页 »</span><br><span>爬虫数据解析</span></a></nav></footer></div><div><div class=pagination__title><span class=pagination__title-h style=font-size:20px>💬评论</span><hr></div><div id=tcomment></div><script src=https://utteranc.es/client.js repo=canw0916/utterances_comments issue-term=title theme=photon-dark crossorigin=anonymous async></script></div></article></main><script async src=https://unpkg.com/mermaid@8.8.1/dist/mermaid.min.js></script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><footer class=footer><span>Copyright
&copy;
2023-2025
<a href=https://canw0916.github.io/en/ style=color:#939393>Felix's Blog</a>
All Rights Reserved
</span><a href=https://beian.miit.gov.cn/ target=_blank style=color:#939393></a>&nbsp;
<span><a target=_blank href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=null" style=display:inline-block;text-decoration:none;height:20px;color:#939393><img src style="float:left;margin:0 5px 0 0">
</a></span><span id=busuanzi_container><link rel=stylesheet href=//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css>总访客数: <span id=busuanzi_value_site_uv></span>
总访问量: <span id=busuanzi_value_site_pv></span></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><span class=topInner><svg class="topSvg" viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
<span id=read_progress></span>
</span></a><script>document.addEventListener("scroll",function(){const t=document.getElementById("read_progress"),n=document.documentElement.scrollHeight,s=document.documentElement.clientHeight,o=document.documentElement.scrollTop||document.body.scrollTop;t.innerText=((o/(n-s)).toFixed(2)*100).toFixed(0)})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>let mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>400||document.documentElement.scrollTop>400?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="📄复制";function s(){t.innerText="👌🏻已复制!",setTimeout(()=>{t.innerText="📄复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){let t=e.textContent+`\r
————————————————\r
版权声明：本文为「Felix's Blog」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\r
原文链接：`+location.href;navigator.clipboard.writeText(t),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild===n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName==="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script src=https://code.jquery.com/jquery-1.12.4.min.js></script><script>$("code[class^=language] ").on("mouseover",function(){this.clientWidth<this.scrollWidth&&$(this).css("width","135%")}).on("mouseout",function(){$(this).css("width","100%")})</script></body></html>